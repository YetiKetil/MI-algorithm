{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import nltk, re, string\n",
    "\n",
    "'''\n",
    "26/06/2018: Upgraded to Pyhton 3\n",
    "### NSM - Marko\n",
    "20/02/2014: BNC version\n",
    "08/07/2014: Revised for error\n",
    "10/07/2013: Fixed idf bug\n",
    "'''\n",
    "\n",
    "class MihalceaSentSimBNC(object):\n",
    "    \"\"\"\n",
    "    Implemented Mihalcea's sentence similarity measure\n",
    "    BNC, version\n",
    "    \"\"\"\n",
    "    ic = None\n",
    "    #information content holder\n",
    "    #tc = None #term count?\n",
    "    idf = {}\n",
    "    debug = False\n",
    "    idf_file = 'bnc.ic'\n",
    "    verbose = False #show detailed output \n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Constructor\n",
    "        '''\n",
    "        #print 'Loading Brown information content ...'\n",
    "        #wnic = WordNetICCorpusReader(nltk.data.find('corpora/wordnet_ic'), '.*\\.dat')\n",
    "        #self.ic = wnic.ic('ic-brown.dat')\n",
    "\n",
    "        '''\n",
    "        Load bnc idf\n",
    "        '''\n",
    "        print('Loading BNC Information Content dictionary ...')\n",
    "        '''\n",
    "        with open(self.idf_file, 'r', encoding=\"utf8\") as bnc_idf:\n",
    "            for line in bnc_idf:\n",
    "                word, score = line.strip().split(',')\n",
    "                self.idf[word] = float(score)\n",
    "        '''\n",
    "        '''\n",
    "        Marko\n",
    "        '''\n",
    "        f = open(self.idf_file, 'r', encoding=\"utf8\")\n",
    "        for line in f:\n",
    "            if line != '\\n':\n",
    "              word, score = line.strip().split(',')\n",
    "              self.idf[word] = float(score)\n",
    "        print('Total of item:',len(self.idf))\n",
    "\n",
    "    # Download nltk resources if not yet available\n",
    "    def download_nltk_resources(self):\n",
    "        nltk.download('punkt')\n",
    "        nltk.download('wordnet')\n",
    "    \n",
    "    #clean and parse the string\n",
    "    #copied from string_processor.py\n",
    "    def clean_string(self, unclean_string):\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "        filtered = []\n",
    "        tokens = nltk.word_tokenize(unclean_string.lower())\n",
    "        for token in tokens:\n",
    "            token = regex.sub('',token)\n",
    "            if not token == '':\n",
    "                filtered.append(token)\n",
    "        return filtered\n",
    "\n",
    "    def find_the_most_similar_word(self, term, tokenized_list):\n",
    "        best_score = 0.\n",
    "        best_term = ''\n",
    "\n",
    "        for compared_term in tokenized_list:\n",
    "            score = self.average_score(term, compared_term)\n",
    "            if score >= best_score:\n",
    "                best_score = score\n",
    "                best_term = compared_term\n",
    "\n",
    "        return best_term, best_score\n",
    "\n",
    "    def average_score(self, word1, word2):\n",
    "        '''\n",
    "        Compute average of WSD scores using the most common synset\n",
    "        '''\n",
    "        #msg = ''\n",
    "        #if self.debug: msg += 'Working on [%s] and [%s].' % (word1, word2)\n",
    "\n",
    "        if word1 == word2:\n",
    "            #if self.debug: print ' Identical words, return 1.'\n",
    "            #print msg\n",
    "            return 1\n",
    "\n",
    "        else:\n",
    "            #Use common synset\n",
    "            synset1 = wn.synsets(word1)\n",
    "            synset2 = wn.synsets(word2)\n",
    "            if len(synset1) ==0 or len(synset2)==0:\n",
    "                #if self.debug: print(' Empty synsets, return 0.')\n",
    "                #print(msg)\n",
    "                return 0\n",
    "            else:\n",
    "                com_synset1 = wn.synsets(word1)[0]\n",
    "                com_synset2 = wn.synsets(word2)[0]\n",
    "\n",
    "                if com_synset1.pos != com_synset2.pos:\n",
    "                    #if self.debug: print(' Incompatible pos, return 0.')\n",
    "                    #print(msg)\n",
    "                    return 0\n",
    "\n",
    "                score = 0\n",
    "                count = 0\n",
    "\n",
    "                #word similarity scoring functions\n",
    "                sim = 0\n",
    "                functions = [wn.wup_similarity, wn.path_similarity, wn.lin_similarity, wn.jcn_similarity]\n",
    "                for func in functions:\n",
    "                    if func == wn.lin_similarity or func == wn.res_similarity:\n",
    "                        try:\n",
    "                            sim = func(com_synset1, com_synset2, self.ic)\n",
    "                            if sim is not None:\n",
    "                                score = score + sim\n",
    "                                count = count + 1\n",
    "                        except:\n",
    "                            None\n",
    "                    else:\n",
    "                        try:\n",
    "                            sim = func(com_synset1, com_synset2)\n",
    "                            if sim is not None:\n",
    "                                score = score + sim\n",
    "                                count = count + 1\n",
    "                        except:\n",
    "                            None\n",
    "\n",
    "                    #if self.debug: msg += ' Sim: %s,%s,%s,%s' % (sim, func, com_synset1, com_synset2)\n",
    "\n",
    "                if score == 0 or count ==0:\n",
    "                    #if self.debug: print '0 score, 0 count'\n",
    "                    #print msg\n",
    "                    return 0\n",
    "                else:\n",
    "                    #if self.debug: print 'Average Sim: %s/%s=%s' % (score, count, score/count)\n",
    "                    #print msg\n",
    "                    return score/count\n",
    "\n",
    "    def similarity(self, sentence1, sentence2, verbose=False):\n",
    "        \n",
    "        self.verbose = verbose\n",
    "                \n",
    "        '''\n",
    "        Similarity function\n",
    "        '''\n",
    "        #sentence1 = self.clean_string(sentence1)\n",
    "        #sentence2 = self.clean_string(sentence2)\n",
    "\n",
    "        list1 = self.clean_string(sentence1)\n",
    "        list2 = self.clean_string(sentence2)\n",
    "\n",
    "        '''\n",
    "        First half\n",
    "        '''\n",
    "        totalTerm1Score = 0\n",
    "        totalTerm1IDF = 0\n",
    "        best_term = ''\n",
    "        idf = 0\n",
    "        for term1 in list1:\n",
    "            if term1 in self.idf:\n",
    "                idf = self.idf[term1]\n",
    "            else:\n",
    "                idf = 0\n",
    "\n",
    "            best_term, score = self.find_the_most_similar_word(term1, list2)\n",
    "            \n",
    "            #print(\"verbose 1st half\")\n",
    "            if self.verbose: print('%s vs %s: %s' % (term1, best_term, score))\n",
    "            \n",
    "            totalTerm1IDF += idf\n",
    "            totalTerm1Score += score*idf\n",
    "\n",
    "        '''\n",
    "        Second half\n",
    "        '''\n",
    "        if self.debug: print('Second half ..\\n\\n')\n",
    "\n",
    "        totalTerm2Score = 0\n",
    "        totalTerm2IDF = 0\n",
    "        for term2 in list2:\n",
    "            if term2 in self.idf:\n",
    "                idf = self.idf[term2]\n",
    "            else:\n",
    "                idf = 0\n",
    "            #print('idf',idf)\n",
    "            best_term, score = self.find_the_most_similar_word(term2, list1)\n",
    "\n",
    "            if self.verbose: print('%s vs %s: %s' % (term2, best_term, score))\n",
    "\n",
    "            totalTerm2IDF += idf\n",
    "            #print(totalTerm2IDF)\n",
    "            totalTerm2Score += score*idf\n",
    "\n",
    "        #first_half = 0\n",
    "\n",
    "        if totalTerm1Score==0 or totalTerm1IDF==0:\n",
    "            first_half = 0\n",
    "        else:\n",
    "            first_half = totalTerm1Score/totalTerm1IDF\n",
    "            if self.debug:\n",
    "                print('first_half: %s/%s = %s' % (totalTerm1Score,totalTerm1IDF,totalTerm1Score/totalTerm1IDF))\n",
    "\n",
    "        #second_half = 0\n",
    "        if totalTerm2Score==0 or totalTerm2IDF==0:\n",
    "            second_half = 0\n",
    "        else:\n",
    "            second_half = totalTerm2Score/totalTerm2IDF\n",
    "            if self.debug:\n",
    "                print('second_half: %s/%s = %s' % (totalTerm2Score,totalTerm2IDF,totalTerm2Score/totalTerm2IDF))\n",
    "\n",
    "        #sim_score = (first_half + second_half)*0.5\n",
    "\n",
    "        return (first_half + second_half)*0.5\n",
    "    \n",
    "    def similarity_files(self, file1, file2, verbose=False):\n",
    "        file1_txt = open(file1, 'r', encoding = \"ISO-8859-1\").read()\n",
    "        file2_txt = open(file2, 'r', encoding = \"ISO-8859-1\").read()\n",
    "        \n",
    "        output = self.similarity(sentence1=file1_txt, sentence2=file2_txt, verbose=verbose)\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BNC Information Content dictionary ...\n",
      "Total of item: 335052\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\marko\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\marko\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "sentsim = MihalceaSentSimBNC()\n",
    "sentsim.download_nltk_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text1: The trainee program provides me with the knowledge and skills I need to do my job well\n",
      "Text2: I have the opportunity for active practice through the trainee program (e.g., using knowledge form sessions, projects in the job\n",
      "0.5715592979534017\n",
      "Wall time: 1.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text1 = \"The trainee program provides me with the knowledge and skills I need to do my job well\"\n",
    "text2 = \"I have the opportunity for active practice through the trainee program (e.g., using knowledge form sessions, projects in the job\"\n",
    "old_res = 0.5715592979534017\n",
    "res = sentsim.similarity(text1, text2)\n",
    "#res = sentsim.similarity(text1, text2, verbose=True) #show detailed output\n",
    "print(\"Text1: {}\\nText2: {}\\n{}\".format(text1, text2, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5715592979534017\n",
      "Wall time: 33.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f1 = 'text1.txt'\n",
    "f2 = 'text2.txt'\n",
    "res = sentsim.similarity_files(f1, f2)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"%%time\\nf1 = 'oppg1.txt'\\nf2 = 'oppg2.txt'\\nres = sentsim.similarity_files(f1, f2)\\nprint(res)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runs 40 mins - code has to be optimized!\n",
    "'''%%time\n",
    "f1 = 'oppg1.txt'\n",
    "f2 = 'oppg2.txt'\n",
    "res = sentsim.similarity_files(f1, f2)\n",
    "print(res)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
